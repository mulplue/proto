# @package _global_

defaults:
  - amp
  - /env/reach

experiment_name: reach

env:
  config:
    amp_obs:
      disable_discriminator: False

algo:
  config:
    task_reward_w: 0.5
    discriminator_reward_w: 0.5

    models:
      reach_model:
        _target_: phys_anim.agents.models.common.Flatten
        config:
          normalize_obs: False
          obs_clamp_value: ${algo.config.obs_clamp_value}
        # Input and output size are the same due to flattening
        num_in: ${env.config.reach_params.obs_size}
        num_out: ${.num_in}

    # Append the direction obs to the actor and critic inputs
    actor:
      config:
        mu_model:
          config:
            extra_inputs:
              reach: ${algo.config.models.reach_model}

    critic:
      config:
        extra_inputs:
          reach: ${algo.config.models.reach_model}

    extra_inputs:
      reach:
        retrieve_from_env: True
        dtype: float
        size: ${algo.config.models.reach_model.num_in}
        env_obs_name: reach_obs
